{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Real_time_webcam_Yolov5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs14Os03I3xm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.backends.cudnn as cudnn\n",
        "import queue\n",
        "from IPython.display import display, Javascript, Image, clear_output\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "\n",
        "from webcamdetect import video_frame, video_stream, js_to_image, bbox_to_bytes"
      ],
      "metadata": {
        "id": "jmGrEji-JAuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/gdrive/MyDrive/yolov5/UNOCards-object-detection/weights/best.pt')  # local repo"
      ],
      "metadata": {
        "id": "kxopo43DI7NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c9756a-ee60-42e5-bd61-3669fafd3120"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 2022-5-17 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 232 layers, 7284276 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/yolov5/UNOCards-object-detection/"
      ],
      "metadata": {
        "id": "SHOmVQMhJEv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260e52ec-dfc0-479e-fb42-bf4e3b67c99e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov5/UNOCards-object-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "bbox = ''\n",
        "# Load the model and set the hyperparameters up\n",
        "cudnn.benchmark = True\n",
        "model.conf = 0.25  # confidence threshold (0-1)\n",
        "model.iou = 0.45  # NMS IoU threshold (0-1)\n",
        "model.classes = None #[0, 15, 16]  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n",
        "\n",
        "my_queue = queue.Queue()\n",
        "def storeInQueue(f):\n",
        "  def wrapper(*args):\n",
        "    my_queue.put(f(*args))\n",
        "  return wrapper\n",
        "\n",
        "@storeInQueue\n",
        "def detection(model, frame, bbox_array):\n",
        "  result = model(frame)\n",
        "  \n",
        "  Class_name = result.pandas().xyxy[0].name\n",
        "  Confidence = result.pandas().xyxy[0].confidence\n",
        "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(Class_name))]\n",
        "  Xmin = result.pandas().xyxy[0].xmin\n",
        "  Ymin = result.pandas().xyxy[0].ymin\n",
        "  Xmax = result.pandas().xyxy[0].xmax\n",
        "  Ymax = result.pandas().xyxy[0].ymax\n",
        "  \n",
        "  _, _, h, w = result.s\n",
        "  img_height, img_width, _ = frame.shape\n",
        "  \n",
        "  width_ratio = img_width/w\n",
        "  height_ratio = img_height/h\n",
        "\n",
        "  for i in range(0, len(Class_name)):\n",
        "    xmin = int(Xmin[i] + 0.5)\n",
        "    ymin = int(Ymin[i] + 0.5)\n",
        "    xmax = int(Xmax[i] + 0.5)\n",
        "    ymax = int(Ymax[i] + 0.5)\n",
        "\n",
        "    xmin = int(xmin * width_ratio)\n",
        "    ymin = int(ymin * height_ratio)\n",
        "    xmax = int(xmax * width_ratio)\n",
        "    ymax = int(ymax * height_ratio)\n",
        "\n",
        "    bbox_array = cv2.rectangle(bbox_array, (xmin, ymin), (xmax, ymax), colors[i], 2)\n",
        "    bbox_array = cv2.putText(bbox_array, Class_name[i],\n",
        "                        (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        colors[i], 2)\n",
        "  bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "  # convert overlay of bbox into bytes\n",
        "  bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "  \n",
        "  # update bbox so next frame gets new overlay\n",
        "  # bbox = bbox_bytes\n",
        "  return bbox_bytes\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  js_reply = video_frame(label_html, bbox)\n",
        "  if not js_reply:\n",
        "    break\n",
        "  \n",
        "  # convert JS response to OpenCV Image\n",
        "  frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "  # create transparent overlay for bounding box\n",
        "  bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "  t1 = threading.Thread(target=detection, args=(model, frame, bbox_array))\n",
        "  t1.start()\n",
        "  #t1.join()\n",
        "  my_data = my_queue.get()\n",
        "  bbox = my_data"
      ],
      "metadata": {
        "id": "M7R5-GTmJGcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}